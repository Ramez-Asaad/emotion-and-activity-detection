# Deep Learning Project: CNN for Image Classification

A modular deep learning project implementing custom CNN architectures for two image classification tasks:
1. **Facial Emotion Recognition** (FER-2013, 7 classes)
2. **Human Activity Recognition** (UCF101 subset, 5 classes)

## ğŸ—ï¸ Project Structure

```
project/
â”œâ”€â”€ models/              # Model architectures
â”‚   â”œâ”€â”€ base_cnn.py     # Base CustomCNN architecture
â”‚   â”œâ”€â”€ emotion_model.py    # FER-2013 specific model
â”‚   â””â”€â”€ activity_model.py   # UCF101 specific model
â”‚
â”œâ”€â”€ configs/            # Configuration files
â”‚   â”œâ”€â”€ base_config.py      # Base configuration
â”‚   â”œâ”€â”€ emotion_config.py   # FER-2013 config
â”‚   â””â”€â”€ activity_config.py  # UCF101 config
â”‚
â”œâ”€â”€ data/               # Data handling
â”‚   â””â”€â”€ transforms.py       # Data augmentation
â”‚
â”œâ”€â”€ utils/              # Utility functions
â”‚   â”œâ”€â”€ training.py         # Training loop
â”‚   â”œâ”€â”€ evaluation.py       # Metrics & evaluation
â”‚   â”œâ”€â”€ checkpoint.py       # Model saving/loading
â”‚   â””â”€â”€ visualization.py    # Plotting functions
â”‚
â”œâ”€â”€ scripts/            # Training & testing scripts
â”‚   â”œâ”€â”€ train_emotion.py    # Train FER-2013 model
â”‚   â”œâ”€â”€ train_activity.py   # Train UCF101 model
â”‚   â””â”€â”€ check_gpu.py        # GPU verification
â”‚
â”œâ”€â”€ checkpoints/        # Saved model checkpoints
â”‚   â”œâ”€â”€ emotion/
â”‚   â””â”€â”€ activity/
â”‚
â”œâ”€â”€ results/            # Training results & logs
â”‚   â”œâ”€â”€ emotion/
â”‚   â””â”€â”€ activity/
â”‚
â””â”€â”€ datasets/           # Dataset storage
    â”œâ”€â”€ FER2013/
    â””â”€â”€ UCF101/
```

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Activate virtual environment
.\venv\Scripts\activate.ps1

# Install dependencies
pip install -r requirements.txt

# Verify GPU
python scripts/check_gpu.py
```

### 2. Prepare Datasets

#### FER-2013 (Emotion Recognition)
Organize your FER-2013 dataset:
```
datasets/FER2013/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Angry/
â”‚   â”œâ”€â”€ Disgust/
â”‚   â”œâ”€â”€ Fear/
â”‚   â”œâ”€â”€ Happy/
â”‚   â”œâ”€â”€ Sad/
â”‚   â”œâ”€â”€ Surprise/
â”‚   â””â”€â”€ Neutral/
â”œâ”€â”€ val/
â”‚   â””â”€â”€ (same structure)
â””â”€â”€ test/
    â””â”€â”€ (same structure)
```

#### UCF101 (Activity Recognition)
Organize your UCF101 subset:
```
datasets/UCF101/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Activity_1/
â”‚   â”œâ”€â”€ Activity_2/
â”‚   â”œâ”€â”€ Activity_3/
â”‚   â”œâ”€â”€ Activity_4/
â”‚   â””â”€â”€ Activity_5/
â”œâ”€â”€ val/
â”‚   â””â”€â”€ (same structure)
â””â”€â”€ test/
    â””â”€â”€ (same structure)
```

### 3. Train Models

#### Train Emotion Recognition Model
```bash
python scripts/train_emotion.py
```

#### Train Activity Recognition Model
```bash
python scripts/train_activity.py
```

## ğŸ¯ Model Architecture

### Base CNN Architecture
- **Input**: 3-channel RGB images (224Ã—224)
- **5 Convolutional Blocks**:
  - Block 1: 3 â†’ 32 channels + MaxPool
  - Block 2: 32 â†’ 64 channels + MaxPool
  - Block 3: 64 â†’ 128 channels + MaxPool
  - Block 4: 128 â†’ 256 channels
  - Block 5: 256 â†’ 256 channels
- **Global Average Pooling**
- **Fully Connected Layer**: 256 â†’ num_classes
- **Total Parameters**: ~981K (0.98M)

### Task-Specific Models

#### EmotionModel (7 classes)
```python
from models.emotion_model import EmotionModel

model = EmotionModel()
# Classes: Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral
```

#### ActivityModel (5 classes)
```python
from models.activity_model import ActivityModel

model = ActivityModel()
# Classes: Configurable based on your UCF101 subset
```

## âš™ï¸ Configuration

Each task has its own configuration file in `configs/`:

- **Base Config** (`base_config.py`): Common hyperparameters
- **Emotion Config** (`emotion_config.py`): FER-2013 specific settings
- **Activity Config** (`activity_config.py`): UCF101 specific settings

### Key Hyperparameters

```python
BATCH_SIZE = 32
NUM_EPOCHS = 50
LEARNING_RATE = 0.001
IMAGE_SIZE = 224
```

Modify these in the respective config files to customize training.

## ğŸ“Š Training Features

- âœ… **Automatic GPU detection** and usage
- âœ… **Data augmentation** (rotation, flip, color jitter)
- âœ… **Learning rate scheduling** (ReduceLROnPlateau)
- âœ… **Early stopping** to prevent overfitting
- âœ… **Checkpoint saving** (best model + periodic saves)
- âœ… **Training visualization** (loss/accuracy curves)
- âœ… **Progress bars** with tqdm

## ğŸ“ˆ Evaluation & Visualization

The project includes comprehensive evaluation utilities:

```python
from utils.evaluation import evaluate_model, print_evaluation_results
from utils.visualization import plot_confusion_matrix

# Evaluate model
results = evaluate_model(model, test_loader, device, class_names)

# Print results
print_evaluation_results(results)

# Plot confusion matrix
plot_confusion_matrix(results['confusion_matrix'], class_names)
```

## ğŸ’» Usage Examples

### Training with Custom Configuration

```python
from configs.emotion_config import EmotionConfig

# Modify configuration
config = EmotionConfig()
config.BATCH_SIZE = 64
config.LEARNING_RATE = 0.0005
config.NUM_EPOCHS = 100

# Train with custom config
# (see scripts/train_emotion.py for full example)
```

### Loading a Trained Model

```python
from models.emotion_model import EmotionModel
from utils.checkpoint import load_checkpoint

model = EmotionModel()
model, _, epoch, metrics = load_checkpoint(
    model, 
    'checkpoints/emotion/best_model.pth',
    device='cuda'
)
```

### Making Predictions

```python
import torch
from models.emotion_model import EmotionModel

model = EmotionModel()
model.load_state_dict(torch.load('checkpoints/emotion/best_model.pth')['model_state_dict'])
model.eval()

# Predict emotion
predicted_class, emotion_label, probabilities = model.predict_emotion(image_tensor)
print(f"Predicted emotion: {emotion_label}")
```

## ğŸ”§ System Requirements

- **Python**: 3.8+
- **PyTorch**: 2.0+ with CUDA 11.8
- **GPU**: NVIDIA GPU with CUDA support (recommended)
- **RAM**: 8GB+ recommended
- **Storage**: ~5GB for datasets + checkpoints

## ğŸ“¦ Dependencies

Core dependencies:
- `torch` - Deep learning framework
- `torchvision` - Computer vision utilities
- `numpy` - Numerical computing
- `matplotlib` - Plotting
- `seaborn` - Statistical visualization
- `scikit-learn` - Metrics and evaluation
- `tqdm` - Progress bars
- `Pillow` - Image processing

Install all dependencies:
```bash
pip install -r requirements.txt
```

## ğŸ“ Project Organization Benefits

1. **Modularity**: Each component has a single responsibility
2. **Reusability**: Shared utilities prevent code duplication
3. **Scalability**: Easy to add new tasks or models
4. **Maintainability**: Clear structure makes code easy to navigate
5. **Professional**: Industry-standard project organization

## ğŸ“ Adding New Tasks

To add a new classification task:

1. Create a new model in `models/your_task_model.py`
2. Create a new config in `configs/your_task_config.py`
3. Create training script in `scripts/train_your_task.py`
4. Organize dataset in `datasets/YourDataset/`
5. Run training!

## ğŸ› Troubleshooting

### GPU Not Detected
```bash
python scripts/check_gpu.py
```
If CUDA is not available, reinstall PyTorch with CUDA support:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Dataset Not Found
Ensure your dataset is organized in the correct structure under `datasets/` folder.

### Out of Memory
Reduce `BATCH_SIZE` in the config file.

## ğŸ“„ License

This project is for educational and research purposes.

## ğŸ‘¥ Authors

Deep Learning Project - Semester 7 (Fall 2025-26)  
Alamein International University

---

**GPU**: NVIDIA GeForce RTX 3050 Ti Laptop GPU  
**Last Updated**: December 2025
